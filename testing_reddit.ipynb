{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run heuristics_helper.ipynb\n",
    "%run graph_helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objFunctions = [obj_disagreement, obj_polarization, obj_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DISAGREEMENT = 0\n",
    "POLARIZATION = 1\n",
    "BOTH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"Reddit.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = data['Reddit'][0,0][0].shape[0]     # number of vertices = 556\n",
    "G = data['Reddit'][0,0][0].toarray()     # adjacency matrix in compressed sparse column format, convert to array\n",
    "nodemap = data['Reddit'][0, 0][1]     # mapping from node ID to labels 1-556 (not important)\n",
    "edges = data['Reddit'][0,0][2]     # list of edges (same as G, not used)\n",
    "s = data['Reddit'][0,0][5]     # labeled \"recent innate opinions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove isolated vertices from the graph\n",
    "s = np.delete(s, 551)\n",
    "s = np.delete(s, 105)\n",
    "s = np.delete(s, 52)\n",
    "n -= 3\n",
    "s = s.reshape((n , 1))\n",
    "\n",
    "G = np.delete(G, 551, 1)\n",
    "G = np.delete(G, 551, 0)\n",
    "G = np.delete(G, 105, 1)\n",
    "G = np.delete(G, 105, 0)\n",
    "G = np.delete(G, 52, 1)\n",
    "G = np.delete(G, 52, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)\n",
    "A = np.linalg.inv(np.identity(n) + L)\n",
    "m = num_edges(L, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distribution of innate opinions\n",
    "plt.hist(s.reshape(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(G.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nxG = nx.from_numpy_matrix(G)\n",
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw(nxG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = n\n",
    "\n",
    "(s, s_greedy, max_obj_greedy_arr, s_local_innate, max_obj_local_innate_arr, s_random, \n",
    "            max_obj_random_arr, s_partial_random, max_obj_partial_random_arr, s_mean, max_obj_mean_arr,\n",
    "            s_deg, max_obj_deg_arr, s_w_deg, max_obj_w_deg_arr, s_double_heuristic, \n",
    "            max_obj_double_heuristic_arr, original_obj) = compare_algorithms(n, k, G, DISAGREEMENT, opinions=s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objs = [max_obj_greedy_arr, max_obj_mean_arr, max_obj_partial_random_arr, max_obj_random_arr, \n",
    "       max_obj_local_innate_arr, max_obj_deg_arr, max_obj_w_deg_arr, max_obj_double_heuristic_arr]\n",
    "\n",
    "df = pd.DataFrame(objs)\n",
    "df = df.transpose()\n",
    "df.columns = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./reddit_pkl/disagreement_connected.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(s, s_greedy, max_obj_greedy_arr, s_local_innate, max_obj_local_innate_arr, s_random, \n",
    "            max_obj_random_arr, s_partial_random, max_obj_partial_random_arr, s_mean, max_obj_mean_arr,\n",
    "            s_deg, max_obj_deg_arr, s_w_deg, max_obj_w_deg_arr, s_double_heuristic, \n",
    "            max_obj_double_heuristic_arr, original_obj) = compare_algorithms(n, k, G, POLARIZATION, opinions=s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objs = [max_obj_greedy_arr, max_obj_mean_arr, max_obj_partial_random_arr, max_obj_random_arr, \n",
    "       max_obj_local_innate_arr, max_obj_deg_arr, max_obj_w_deg_arr, max_obj_double_heuristic_arr]\n",
    "\n",
    "df = pd.DataFrame(objs)\n",
    "df = df.transpose()\n",
    "df.columns = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./reddit_pkl/polarization_connected.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(s, s_greedy, max_obj_greedy_arr, s_local_innate, max_obj_local_innate_arr, s_random, \n",
    "            max_obj_random_arr, s_partial_random, max_obj_partial_random_arr, s_mean, max_obj_mean_arr,\n",
    "            s_deg, max_obj_deg_arr, s_w_deg, max_obj_w_deg_arr, s_double_heuristic, \n",
    "            max_obj_double_heuristic_arr, original_obj) = compare_algorithms(n, k, G, BOTH, opinions=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objs = [max_obj_greedy_arr, max_obj_mean_arr, max_obj_partial_random_arr, max_obj_random_arr, \n",
    "       max_obj_local_innate_arr, max_obj_deg_arr, max_obj_w_deg_arr, max_obj_double_heuristic_arr]\n",
    "\n",
    "df = pd.DataFrame(objs)\n",
    "df = df.transpose()\n",
    "df.columns = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./reddit_pkl/sum_connected.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
